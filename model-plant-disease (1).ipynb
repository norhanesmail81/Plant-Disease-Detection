{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3023132,"sourceType":"datasetVersion","datasetId":1851550}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T00:44:25.861237Z","iopub.execute_input":"2025-09-17T00:44:25.861564Z","iopub.status.idle":"2025-09-17T00:45:03.989553Z","shell.execute_reply.started":"2025-09-17T00:44:25.861530Z","shell.execute_reply":"2025-09-17T00:45:03.988535Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T00:45:03.991377Z","iopub.execute_input":"2025-09-17T00:45:03.991799Z","iopub.status.idle":"2025-09-17T00:45:12.732356Z","shell.execute_reply.started":"2025-09-17T00:45:03.991776Z","shell.execute_reply":"2025-09-17T00:45:12.731484Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Device configuration\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T00:48:20.103998Z","iopub.execute_input":"2025-09-17T00:48:20.104420Z","iopub.status.idle":"2025-09-17T00:48:20.112972Z","shell.execute_reply.started":"2025-09-17T00:48:20.104390Z","shell.execute_reply":"2025-09-17T00:48:20.111956Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Hyperparameters\nnum_classes = 38  # عدد الفئات في الداتا\nnum_epochs = 10\nbatch_size = 32\nlearning_rate = 0.001","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T00:48:22.252565Z","iopub.execute_input":"2025-09-17T00:48:22.252915Z","iopub.status.idle":"2025-09-17T00:48:22.257624Z","shell.execute_reply.started":"2025-09-17T00:48:22.252886Z","shell.execute_reply":"2025-09-17T00:48:22.256592Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Data augmentation and normalization\ntransform = transforms.Compose([\n    transforms.Resize((128, 128)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T00:48:24.798575Z","iopub.execute_input":"2025-09-17T00:48:24.798888Z","iopub.status.idle":"2025-09-17T00:48:24.804739Z","shell.execute_reply.started":"2025-09-17T00:48:24.798868Z","shell.execute_reply":"2025-09-17T00:48:24.803770Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load dataset\ntrain_dataset = torchvision.datasets.ImageFolder(\n    root=\"/kaggle/input/leaf-disease-dataset-combination/image data/train\",\n    transform=transform\n)\n\ntest_dataset = torchvision.datasets.ImageFolder(\n    root=\"/kaggle/input/leaf-disease-dataset-combination/image data/test\",\n    transform=transform\n)\n\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T00:48:26.429363Z","iopub.execute_input":"2025-09-17T00:48:26.429673Z","iopub.status.idle":"2025-09-17T00:48:37.544125Z","shell.execute_reply.started":"2025-09-17T00:48:26.429650Z","shell.execute_reply":"2025-09-17T00:48:37.543237Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define a simple CNN model\nclass SimpleCNN(nn.Module):\n    def __init__(self, num_classes):\n        super(SimpleCNN, self).__init__()\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2)\n        )\n        self.layer2 = nn.Sequential(\n            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2)\n        )\n        self.global_pool = nn.AdaptiveAvgPool2d((7, 7))  # ⬅️ يضمن حجم ثابت\n        self.fc1 = nn.Linear(64*7*7, 256)\n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(256, num_classes)\n\n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = self.global_pool(out)\n        out = out.view(out.size(0), -1)\n        out = self.fc1(out)\n        out = self.relu(out)\n        out = self.fc2(out)\n        return out\n\nmodel = SimpleCNN(num_classes).to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T00:57:35.268844Z","iopub.execute_input":"2025-09-17T00:57:35.269566Z","iopub.status.idle":"2025-09-17T00:57:35.286625Z","shell.execute_reply.started":"2025-09-17T00:57:35.269536Z","shell.execute_reply":"2025-09-17T00:57:35.285639Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T00:57:49.083471Z","iopub.execute_input":"2025-09-17T00:57:49.084103Z","iopub.status.idle":"2025-09-17T00:57:49.089532Z","shell.execute_reply.started":"2025-09-17T00:57:49.084067Z","shell.execute_reply":"2025-09-17T00:57:49.088406Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training and Validation Loop\ntrain_losses, val_losses = [], []\ntrain_accs, val_accs = [], []\n\nfor epoch in range(num_epochs):\n    # ---- Training ----\n    model.train()\n    running_loss, correct, total = 0.0, 0, 0\n\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    train_acc = 100 * correct / total\n    train_losses.append(running_loss/len(train_loader))\n    train_accs.append(train_acc)\n\n    # ---- Validation ----\n    model.eval()\n    val_loss, val_correct, val_total = 0.0, 0, 0\n\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n\n            _, predicted = torch.max(outputs.data, 1)\n            val_total += labels.size(0)\n            val_correct += (predicted == labels).sum().item()\n\n    val_acc = 100 * val_correct / val_total\n    val_losses.append(val_loss/len(test_loader))\n    val_accs.append(val_acc)\n\n    print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n          f\"Train Loss: {train_losses[-1]:.4f}, Train Acc: {train_acc:.2f}% | \"\n          f\"Val Loss: {val_losses[-1]:.4f}, Val Acc: {val_acc:.2f}%\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T01:04:58.347644Z","iopub.execute_input":"2025-09-17T01:04:58.348031Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ✅ Plot Loss Curve\nplt.figure(figsize=(8,5))\nplt.plot(train_losses, label=\"Train Loss\")\nplt.plot(val_losses, label=\"Validation Loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Training vs Validation Loss\")\nplt.legend()\nplt.show()\n\n# ✅ Evaluate Model\nall_preds, all_labels = [], []\nmodel.eval()\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        all_preds.extend(predicted.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\n# ✅ Confusion Matrix\ncm = confusion_matrix(all_labels, all_preds)\nplt.figure(figsize=(10,8))\nsns.heatmap(cm, annot=False, cmap=\"Blues\")\nplt.title(\"Confusion Matrix\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T01:03:26.034258Z","iopub.status.idle":"2025-09-17T01:03:26.034553Z","shell.execute_reply.started":"2025-09-17T01:03:26.034426Z","shell.execute_reply":"2025-09-17T01:03:26.034438Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ✅ Classification Report\nprint(classification_report(all_labels, all_preds, target_names=test_dataset.classes))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T01:03:26.036261Z","iopub.status.idle":"2025-09-17T01:03:26.036584Z","shell.execute_reply.started":"2025-09-17T01:03:26.036451Z","shell.execute_reply":"2025-09-17T01:03:26.036467Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}